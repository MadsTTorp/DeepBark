{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to run RAG setup basic (v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import bs4 \n",
    "import getpass\n",
    "import requests\n",
    "import faiss \n",
    "import numpy as np\n",
    "\n",
    "from typing import Literal\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, Annotated, TypedDict\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from utils import *\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialize model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single document extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://petguide.dk/hundefoder-maerker/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"entry-content single-page\", \"entry-title\", \"entry-meta uppercase is-xsmall\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the text splitter \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "\n",
    "total_documents = len(docs)\n",
    "third = total_documents // 3\n",
    "\n",
    "# Split the documents into chunks\n",
    "all_splits = []\n",
    "for doc in docs:\n",
    "    splits = text_splitter.split_documents([doc])\n",
    "    num_splits = len(splits)\n",
    "    third = num_splits // 3\n",
    "    \n",
    "    for i, split in enumerate(splits):\n",
    "        split.metadata[\"source\"] = doc.metadata.get(\"source\", \"Unknown\")\n",
    "        if i < third:\n",
    "            split.metadata[\"section\"] = \"beginning\"\n",
    "        elif i < 2 * third:\n",
    "            split.metadata[\"section\"] = \"middle\"\n",
    "        else:\n",
    "            split.metadata[\"section\"] = \"end\"\n",
    "    all_splits.extend(splits)\n",
    "    \n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for each chunk\n",
    "embeddings_list = [embeddings.embed_query(doc.page_content) for doc in all_splits]\n",
    "embeddings_array = np.array(embeddings_list)\n",
    "\n",
    "# Create a FAISS index\n",
    "dimension = embeddings_array.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple documents extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://petguide.dk/bloggen/\"\n",
    "print(f'Getting article links from {main_url}...')\n",
    "article_links = get_article_links(main_url)\n",
    "print(f'Found {len(article_links)} article links...')\n",
    "all_splits, index = load_and_chunk_documents(article_links[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_rag_prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithSources(TypedDict):\n",
    "    \"\"\"An answer to the question, with sources.\"\"\"\n",
    "    answer: str\n",
    "    sources: Annotated[\n",
    "        List[str],\n",
    "        ...,\n",
    "        \"List of sources (author + year) used to answer the question\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: AnswerWithSources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    # Create embeddings for the query\n",
    "    query_embedding = embeddings.embed_query(state[\"question\"])\n",
    "    query_embedding = np.array([query_embedding])\n",
    "    \n",
    "    # Perform similarity search\n",
    "    distances, indices = index.search(query_embedding, k=5)\n",
    "    retrieved_docs = [all_splits[i] for i in indices[0]]\n",
    "    print(f\"Retrieved {len(retrieved_docs)} documents for the question: {state['question']}\")\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = custom_rag_prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    structured_llm = llm.with_structured_output(AnswerWithSources)\n",
    "    response = structured_llm.invoke(messages)\n",
    "    # Extract unique URLs from the context\n",
    "    unique_urls = list({doc.metadata['source'] for doc in state[\"context\"]})\n",
    "    \n",
    "    # Update the response with the unique URLs\n",
    "    response['sources'] = unique_urls\n",
    "    \n",
    "    state['answer'] = response\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": \"Hvilket fodermærke er rig på protein, fedt, er kornfrit og produceres i Canada?\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woofwisdom-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
